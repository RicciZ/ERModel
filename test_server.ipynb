{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, device, use_hrv,\n",
    "            dropout_cnn = 0.5, dropout_lstm = 0.8, kernel_size_pool = 5, stride_pool = 4):\n",
    "        super(ERModel, self).__init__()\n",
    "        self.device = device\n",
    "        self.use_hrv = use_hrv\n",
    "        # CNN stream\n",
    "        self.conv1 = nn.Conv1d(in_channels=2, out_channels=8, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv1d(in_channels=8, out_channels=16, kernel_size=3, padding=1)\n",
    "        self.conv3 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=3, padding=1)\n",
    "        self.dropout_cnn = nn.Dropout(p=dropout_cnn)\n",
    "        self.dropout_lstm = nn.Dropout(p=dropout_lstm)\n",
    "        self.pool = nn.AvgPool1d(kernel_size=kernel_size_pool, stride=stride_pool)\n",
    "        # BLSTM stream\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        # batch x time_seq x features\n",
    "        self.blstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, bidirectional=True)\n",
    "        self.fc1 = nn.Linear(hidden_size*2 + 64*int((input_size-kernel_size_pool)/4+1), 256)\n",
    "        self.fc2 = nn.Linear(256, 32)\n",
    "        if self.use_hrv:\n",
    "            self.fc3 = nn.Linear(36, num_classes)\n",
    "        else:\n",
    "            self.fc3 = nn.Linear(32, num_classes)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.bn2 = nn.BatchNorm1d(32)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.use_hrv:\n",
    "            x_hrv = x[:,:,-2:]\n",
    "            x = x[:,:,:-2]\n",
    "            # print(x_hrv.shape,x.shape)\n",
    "        # BLSTM stream\n",
    "        h0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(self.device)\n",
    "        c0 = torch.zeros(self.num_layers*2, x.size(0), self.hidden_size).to(self.device)\n",
    "        out, _ = self.blstm(x, (h0, c0))\n",
    "        out = self.dropout_lstm(out[:, -1, :])\n",
    "\n",
    "        # CNN stream\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.dropout_cnn(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.dropout_cnn(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.dropout_cnn(x)\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = self.dropout_cnn(x)\n",
    "        x = self.pool(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        \n",
    "        # concatenate and fc\n",
    "        x = torch.cat((x,out),1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        # print(x.shape)\n",
    "        x = torch.cat((x, x_hrv.reshape(x_hrv.shape[0], -1)),1)\n",
    "        # print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ERonServer:\n",
    "    def __init__(self):\n",
    "        # model\n",
    "        num_classes = 3\n",
    "        self.input_size = 60000\n",
    "        hidden_size = 512\n",
    "        num_layers = 2\n",
    "        lr = 0.001\n",
    "        use_hrv = True\n",
    "        device = torch.device(\"cpu\")\n",
    "        self.model = ERModel(self.input_size, hidden_size, num_layers, num_classes, device, use_hrv).to(device)\n",
    "        # criterion = nn.MSELoss()\n",
    "        # optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "        checkpoint = torch.load(os.path.join('checkpoint/my_checkpoint.pth.tar'), map_location=\"cpu\")\n",
    "        self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        # self.optimizer.load_state_dict(checkpoint['optimizer'])\n",
    "    \n",
    "    \n",
    "    def get_emo(self, filename):\n",
    "        ecg = pd.read_csv(filename)\n",
    "        x = np.array([i for i in ecg['信号强度'] if i != 0])\n",
    "        x = (x-np.mean(x))/np.std(x)\n",
    "        x = torch.tensor([x,x])\n",
    "        x = torch.cat((x, torch.zeros(2, self.input_size - x.shape[1])),1)\n",
    "        ibi = np.array([i/200 for i in ecg['IBI'] if i != 0])\n",
    "        mean = np.mean(ibi)\n",
    "        std = np.std(ibi)\n",
    "        x = torch.cat((x, torch.tensor([[mean,std], [mean,std]])),1).unsqueeze(0).float()\n",
    "        res = self.model(x)\n",
    "        res = res[0].detach().numpy()\n",
    "        print('res',res)\n",
    "        emo = self.map_score_emo(res)\n",
    "        \n",
    "        return emo\n",
    "\n",
    "    \n",
    "    def map_score_emo(self, score):\n",
    "        # map 3 scores to specific emotion: \n",
    "        # calmness 322, happiness 433, fear 244, sadness 133, anger 144, excitement 333\n",
    "        \n",
    "        # val positive or negative\n",
    "        # aro bored or excited\n",
    "        # dom without control or empowered\n",
    "        print('score', score)\n",
    "        emotion = np.array([[3.17, 2.26, 2.09], [4.39, 3.44, 3.65], [2.26, 3.67, 3.67], \n",
    "                        [1.52, 3.00, 3.96], [1.85, 3.09, 3.37], [3.44, 3.53, 3.39]])\n",
    "        out = np.zeros(6)\n",
    "        for i in range(len(emotion)):\n",
    "            temp = (score - emotion[i])**2\n",
    "            out[i] = 100*(2*temp[0] + temp[1] + temp[2])\n",
    "        out = max(out)-out+1\n",
    "        out /= sum(out)\n",
    "        print('out', out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = ERonServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res [11.175746   7.9443026 11.964632 ]\n",
      "score [11.175746   7.9443026 11.964632 ]\n",
      "out [8.27495976e-02 4.55211184e-01 1.40949358e-01 4.86947614e-05\n",
      " 1.76571750e-02 3.03383991e-01]\n"
     ]
    }
   ],
   "source": [
    "emo = test.get_emo(\"user_ecg/2022_5_18_13_49.csv\")\n",
    "emo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(emo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ERCode]",
   "language": "python",
   "name": "conda-env-ERCode-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
